[llm]
provider = "ollama"       # "ollama" | "anthropic"

[llm.ollama]
host = "localhost"
port = 11434
model = "llama3.1:8b"

[llm.anthropic]
api_key = ""
model = "claude-haiku-4-5-20251001"
