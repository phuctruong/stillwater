# AI Steroids Results (Consolidated)

> Generated by `python -m stillwater.gen_ai_steroids_readme` (or `stillwater gen-ai-steroids-readme`).

This folder contains human-readable score reports for “model on Stillwater skills” evaluations.

Two different things are mixed in these reports:
1) **Spec-based scoring** (reading `skills/*.md` and rating expected discipline/auditability uplift)
2) **Receipt-based benchmarking** (running the deterministic A/B harness that emits artifacts under `artifacts/skills_ab/`)

If you want replayable evidence, use the harness (`python -m stillwater.skills_ab`).

## Files

- `gemini3-flash-on-steroids.md`
- `gpt5.1-mini-on-ai-steroids.md`
- `gpt5.2-on-ai-steroids.md`
- `gpt5.3-on-ai-steroids.md`

## Rubric (shared)

All the `gpt5.*` reports use a similar rubric: **1–10** scoring for how well each skill pushes the model toward:
- determinism (repeatable process)
- evidence/receipts (Red→Green gates; “no green without proof”)
- bounded scope + stop rules
- auditability (why actions happened)
- safe tool use + fail-closed refusal/NEED_INFO

## Consolidated scores (by skill)

These are the “before → after” numbers as reported in each file (not re-measured here).

| Skill | Gemini 3 Flash | GPT-5.1 mini | GPT-5.2 | GPT-5.3 |
|---|:---:|:---:|:---:|:---:|
| `prime-coder.md` | 7 → 9 | 6 → 9 | 7 → 9 | 8 → 9 |
| `prime-math.md` | 0 → 10 | 4 → 9 | 6 → 9 | 7 → 9 |
| `prime-safety.md` | 4 → 10 | 5 → 9 | 6 → 9 | 7 → 9 |
| `phuc-context.md` | 6 → 10 | 5 → 8 | 6 → 8 | 7 → 8 |
| `phuc-forecast.md` | n/a | 5 → 9 | 6 → 9 | 7 → 9 |
| `phuc-swarms.md` | n/a | 4 → 8 | 5 → 8 | 6 → 8 |
| `phuc-cleanup.md` | n/a | 5 → 7 | 6 → 7 | 6 → 7 |

Notes:
- The Gemini report only assigns explicit “Score: X/10” for a subset of skills; missing entries are `n/a`.
- `gpt5.3-on-ai-steroids.md` is explicitly spec-based expectation scoring (not a receipt-backed run).

## What’s actually reproducible (receipts)

The repo’s receipts generator for these move-cards is the skills A/B harness:

```bash
PYTHONPATH=src/cli/src STILLWATER_AB_BACKEND=mock STILLWATER_AB_CACHE=0 \
  python -m stillwater.skills_ab
```

Outputs:
- `artifacts/skills_ab/results.json` (machine-readable)
- `artifacts/skills_ab/report.md` (human-readable)

The notebook `PHUC-SKILLS-SECRET-SAUCE.ipynb` is a thin UI wrapper over the same harness.
